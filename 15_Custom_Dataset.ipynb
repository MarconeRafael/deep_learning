{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf78b4e9",
      "metadata": {
        "id": "cf78b4e9"
      },
      "source": [
        "# Atividade: CNNs para Classifica√ß√£o\n",
        "\n",
        "Neste notebook, iremos preparar nosso pr√≥prio dataset e treinar um modelo de classifica√ß√£o de imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108587c0",
      "metadata": {
        "id": "108587c0"
      },
      "source": [
        "## Preparando os dados\n",
        "\n",
        "Os dados desta atividade ser√£o baixados da internet. Utilizaremos para isso buscadores comuns. Em seguida, dividiremos em treinamento e valida√ß√£o."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QYnJifmZCQO",
        "outputId": "234db8ee-b78c-4518-980c-cc38d4224a3f"
      },
      "id": "7QYnJifmZCQO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from icrawler) (4.13.5)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from icrawler) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from icrawler) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from icrawler) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->icrawler) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->icrawler) (2025.10.5)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b74ce50",
      "metadata": {
        "id": "7b74ce50"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from icrawler.builtin import GoogleImageCrawler, BingImageCrawler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98d4ebb",
      "metadata": {
        "id": "b98d4ebb"
      },
      "source": [
        "### Adquirindo as Imagens\n",
        "\n",
        "Utilizaremos o iCrawler para baixar imagens em buscadores atrav√©s de termos especificados. Defina sua lista de classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2c5e01",
      "metadata": {
        "id": "bb2c5e01"
      },
      "outputs": [],
      "source": [
        "def download_images(keyword, folder, n_total=100):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    downloaded = len(os.listdir(folder))\n",
        "    remaining = n_total - downloaded\n",
        "\n",
        "    while downloaded < n_total:\n",
        "        crawler = GoogleImageCrawler(storage={'root_dir': folder})\n",
        "        crawler.crawl(keyword=keyword, max_num=remaining, file_idx_offset=downloaded)\n",
        "        downloaded = len(os.listdir(folder))\n",
        "        remaining = n_total - downloaded\n",
        "        print(f\"Downloaded {downloaded}/{n_total}\")\n",
        "\n",
        "    print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4008f42c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4008f42c",
        "outputId": "7ffe95dd-4ab6-4cab-e874-cfb0736b0a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando download para a classe: Goku...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e4c50>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e5190>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e5700>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e6090>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e6600>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c380e6ae0>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c38662690>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c386683b0>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c386691c0>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://w7.png, error: HTTPSConnectionPool(host='w7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c3866e0c0>: Failed to resolve 'w7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://w7.png, error: HTTPSConnectionPool(host='w7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c3866aea0>: Failed to resolve 'w7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://w7.png, error: HTTPSConnectionPool(host='w7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c38669fd0>: Failed to resolve 'w7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 403, file https://preview.redd.it/any-way-to-watch-dbz-in-high-quality-it-looks-very-blurry-v0-34j6cu5ljfvf1.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 66/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2a9d5a60>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2a9d7440>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://e7.png, error: HTTPSConnectionPool(host='e7.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2a9d78f0>: Failed to resolve 'e7.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa04080>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa04590>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa04a10>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa04ec0>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa07170>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://e1.png, error: HTTPSConnectionPool(host='e1.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2aa04530>: Failed to resolve 'e1.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 100/100\n",
            "Download complete!\n",
            "Iniciando download para a classe: Vegeta...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 404, file https://static.wikia.nocookie.net/nerddragon/images/f/f5/Vegeta_Saga_Saiyajin_%28Forma_Base%29.png\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f172c0>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f30530>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f320c0>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 404, file https://www.itl.cat/png\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f33c80>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f32840>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f32cc0>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://spng, error: HTTPSConnectionPool(host='spng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f304a0>: Failed to resolve 'spng' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://spng, error: HTTPSConnectionPool(host='spng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f33b60>: Failed to resolve 'spng' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://spng, error: HTTPSConnectionPool(host='spng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f582c0>: Failed to resolve 'spng' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 500, file https://www.google.com/search/about-this-image?img=H4sIAAAAAAAA_-MS4bi-_cmaHW2zD2QIPGv-37pk-8qjpg\n",
            "ERROR:downloader:Response status code 404, file https://static.wikia.nocookie.net/liberproeliis/images/3/39/Vegeta_by_maffo1989-d7avdoe.png\n",
            "ERROR:downloader:Exception caught when downloading file https://p.kindpng, error: HTTPSConnectionPool(host='p.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c3866acf0>: Failed to resolve 'p.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://p.kindpng, error: HTTPSConnectionPool(host='p.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f33500>: Failed to resolve 'p.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://p.kindpng, error: HTTPSConnectionPool(host='p.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f32ba0>: Failed to resolve 'p.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Exception caught when downloading file https://www.seekpng, error: HTTPSConnectionPool(host='www.seekpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c2a9d7020>: Failed to resolve 'www.seekpng' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.seekpng, error: HTTPSConnectionPool(host='www.seekpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f16e40>: Failed to resolve 'www.seekpng' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.seekpng, error: HTTPSConnectionPool(host='www.seekpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c29f16690>: Failed to resolve 'www.seekpng' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 68/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 404, file https://static.wikia.nocookie.net/nerddragon/images/f/f5/Vegeta_Saga_Saiyajin_%28Forma_Base%29.png\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385c21e0>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385bb650>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.kindpng, error: HTTPSConnectionPool(host='www.kindpng', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385baf30>: Failed to resolve 'www.kindpng' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n",
            "ERROR:downloader:Response status code 404, file https://www.itl.cat/png\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385ba780>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 2\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385ba1e0>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 1\n",
            "ERROR:downloader:Exception caught when downloading file https://www.png, error: HTTPSConnectionPool(host='www.png', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7b8c385b9d00>: Failed to resolve 'www.png' ([Errno -2] Name or service not known)\")), remaining retry times: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 100/100\n",
            "Download complete!\n",
            "\n",
            "Todos os downloads foram conclu√≠dos.\n"
          ]
        }
      ],
      "source": [
        "# Definindo as duas classes e seus respectivos termos de busca\n",
        "search_terms = {\n",
        "    # Chave (Nome da Pasta): Valor (Palavra-Chave para a Busca)\n",
        "    \"Goku\": \"Goku Dragon Ball z alta qualidade\",\n",
        "    \"Vegeta\": \"Vegeta Dragon Ball z alta qualidade\",\n",
        "}\n",
        "\n",
        "\n",
        "base_folder = \"data/anime_dbz\"\n",
        "\n",
        "for label, term in search_terms.items():\n",
        "    print(f\"Iniciando download para a classe: {label}...\")\n",
        "\n",
        "    # A vari√°vel 'label' agora define o nome da pasta\n",
        "    download_images(term, f\"{base_folder}/{label}\", n_total=100)\n",
        "\n",
        "print(\"\\nTodos os downloads foram conclu√≠dos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d931e35",
      "metadata": {
        "id": "0d931e35"
      },
      "source": [
        "### Treinamento e Valida√ß√£o\n",
        "\n",
        "Dividiremos as imagens baixadas nas pastas `train` e `val`. Defina uma porcentagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88181559",
      "metadata": {
        "id": "88181559"
      },
      "outputs": [],
      "source": [
        "def split_train_val(root_dir, train_ratio=0.8, seed=42):\n",
        "    random.seed(seed)\n",
        "\n",
        "    train_dir = root_dir + \"_split/train\"\n",
        "    val_dir = root_dir + \"_split/val\"\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = [os.path.join(class_path, f) for f in os.listdir(class_path)]\n",
        "        images = [f for f in images if os.path.isfile(f)]\n",
        "        random.shuffle(images)\n",
        "\n",
        "        n_train = int(len(images) * train_ratio)\n",
        "\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        for img in images[:n_train]:\n",
        "            shutil.copy(img, os.path.join(train_class_dir, os.path.basename(img)))\n",
        "        for img in images[n_train:]:\n",
        "            shutil.copy(img, os.path.join(val_class_dir, os.path.basename(img)))\n",
        "\n",
        "        print(f\"{class_name}: {n_train} train, {len(images)-n_train} val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9974e910",
      "metadata": {
        "id": "9974e910"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Implemente um Dataset PyTorch que carregue as imagens baixadas com suas respectivas classes. Aplique data augmentation e carregue em batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91b901e",
      "metadata": {
        "id": "f91b901e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- 1. Defini√ß√£o da Classe Dataset Personalizada (COM DEBUG) ---\n",
        "class AnimeDataset(Dataset):\n",
        "    # ... (restante do c√≥digo igual)\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Mapeamento de nome de pasta (classe) para √≠ndice num√©rico\n",
        "        self.class_to_idx = {\n",
        "            'Goku': 0,\n",
        "            'Vegeta': 1\n",
        "        }\n",
        "\n",
        "        print(f\"\\n[DEBUG DATASET] Iniciando busca em: {self.root_dir}\")\n",
        "\n",
        "        # Preenche as listas de caminhos e r√≥tulos\n",
        "        for class_name, idx in self.class_to_idx.items():\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "\n",
        "            if os.path.isdir(class_path):\n",
        "                # Tenta listar os arquivos APENAS se o diret√≥rio existir\n",
        "                try:\n",
        "                    filenames = os.listdir(class_path)\n",
        "\n",
        "                    # Filtra apenas arquivos (exclui pastas ocultas, etc.)\n",
        "                    valid_files = [f for f in filenames if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "                    if len(valid_files) == 0:\n",
        "                         print(f\"[DEBUG DATASET] A pasta '{class_name}' est√° VAZIA. Caminho: {class_path}\")\n",
        "                         continue # Pula para a pr√≥xima classe\n",
        "\n",
        "                    for filename in valid_files:\n",
        "                        self.image_paths.append(os.path.join(class_path, filename))\n",
        "                        self.labels.append(idx)\n",
        "\n",
        "                    print(f\"[DEBUG DATASET] Classe '{class_name}' adicionada com {len(valid_files)} imagens.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"[DEBUG DATASET] ERRO de permiss√£o/leitura em {class_path}. Erro: {e}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"[DEBUG DATASET] Pasta de classe N√ÉO ENCONTRADA para '{class_name}'. Esperado em: {class_path}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Implementa√ß√£o de tratamento de erros com try-except\n",
        "        try:\n",
        "            # 1. Carregar a Imagem\n",
        "            img_path = self.image_paths[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "\n",
        "            # 2. Aplicar Transforma√ß√µes\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "\n",
        "        except Exception as e:\n",
        "            # Em caso de erro (ex: arquivo corrompido, erro de leitura)\n",
        "            print(f\"Erro ao carregar imagem em {self.image_paths[idx]}. Erro: {e}\")\n",
        "            # Retorna um elemento aleat√≥rio para n√£o quebrar o batching\n",
        "            # Isso √© uma solu√ß√£o simples; em produ√ß√£o, voc√™ pularia este item.\n",
        "            # Aqui, tentamos uma solu√ß√£o para continuar o treinamento:\n",
        "\n",
        "            # Escolhe um novo √≠ndice aleat√≥rio (que n√£o seja o atual)\n",
        "            new_idx = random.randint(0, len(self) - 1)\n",
        "            if new_idx == idx:\n",
        "                new_idx = (new_idx + 1) % len(self)\n",
        "\n",
        "            return self.__getitem__(new_idx)\n",
        "\n",
        "\n",
        "# --- 2. Defini√ß√£o das Transforma√ß√µes e Data Augmentation ---\n",
        "def get_transforms(image_size=224):\n",
        "    \"\"\"Define as transforma√ß√µes para treino (com augmentation) e valida√ß√£o.\"\"\"\n",
        "\n",
        "    # Transforma√ß√µes para o conjunto de TREINO (com Data Augmentation)\n",
        "    train_transforms = transforms.Compose([\n",
        "        # Data Augmentation:\n",
        "        transforms.Resize((image_size, image_size)), # Redimensiona para um tamanho padr√£o\n",
        "        transforms.RandomRotation(15),             # Rota√ß√£o aleat√≥ria de at√© 15 graus\n",
        "        transforms.RandomHorizontalFlip(p=0.5),    # Flip horizontal aleat√≥rio\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1), # Varia√ß√µes de cor/brilho\n",
        "\n",
        "        # Convers√£o e Normaliza√ß√£o (Essencial para pr√©-treinamento - ImageNet)\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Transforma√ß√µes para o conjunto de VALIDA√á√ÉO/TESTE (SEM Data Augmentation)\n",
        "    # Apenas redimensiona, converte e normaliza\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transforms, val_transforms\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Fun√ß√£o de Implementa√ß√£o e Carregamento (DataLoader) ---\n",
        "def create_dataloaders(root_dir, batch_size=32, image_size=224):\n",
        "    \"\"\"Cria e retorna os DataLoaders de Treino e Valida√ß√£o.\"\"\"\n",
        "\n",
        "    # üö® Modifica√ß√£o: A fun√ß√£o create_dataloaders deve receber o caminho base do SPLIT.\n",
        "    # Ex: /content/data/anime_dbz_split\n",
        "\n",
        "\n",
        "\n",
        "    if root_dir.endswith('/'):\n",
        "        root_dir = root_dir[:-1] # Remove barra final, se houver\n",
        "\n",
        "    # Assume que a pasta de treino/valida√ß√£o est√° em {root_dir}/train e {root_dir}/val\n",
        "    train_dir = os.path.join(root_dir, \"train\")\n",
        "    val_dir = os.path.join(root_dir, \"val\")\n",
        "\n",
        "    # --- NOVO: Verifica√ß√£o do ponto de partida ---\n",
        "    print(f\"\\n[DEBUG LOADER] Verificando diret√≥rios esperados:\")\n",
        "    print(f\"[DEBUG LOADER] Treino: {train_dir}\")\n",
        "    print(f\"[DEBUG LOADER] Valida√ß√£o: {val_dir}\")\n",
        "\n",
        "    if not os.path.isdir(train_dir) or not os.path.isdir(val_dir):\n",
        "        print(\"ERRO CR√çTICO: Pastas 'train' e/ou 'val' n√£o foram encontradas. O caminho base do split est√° incorreto.\")\n",
        "        print(\"Verifique se o seu 'root_dir' na chamada √© a pasta que cont√©m 'train' e 'val'.\")\n",
        "        return None, None\n",
        "    # ---------------------------------------------\n",
        "\n",
        "    train_transforms, val_transforms = get_transforms(image_size)\n",
        "\n",
        "    try:\n",
        "        # Cria os Datasets (aqui o erro num_samples=0 ser√° detectado pelos prints internos)\n",
        "        train_dataset = AnimeDataset(root_dir=train_dir, transform=train_transforms)\n",
        "        val_dataset = AnimeDataset(root_dir=val_dir, transform=val_transforms)\n",
        "\n",
        "        # O c√≥digo a seguir s√≥ ser√° executado se len(train_dataset) e len(val_dataset) > 0\n",
        "\n",
        "        if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "             # Este raise agora ser√° mais espec√≠fico com a informa√ß√£o de debug\n",
        "             raise ValueError(\"Dataset vazio. Verifique os prints de debug acima para saber qual pasta falhou.\")\n",
        "\n",
        "        # ... (Cria√ß√£o dos DataLoaders)\n",
        "\n",
        "        print(f\"Datasets carregados: Treino ({len(train_dataset)} imagens), Valida√ß√£o ({len(val_dataset)} imagens)\")\n",
        "\n",
        "        return train_dataloader, val_dataloader\n",
        "\n",
        "    except Exception as e:\n",
        "        # ... (Tratamento de erro existente)\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "VOZf5oohgCBw"
      },
      "id": "VOZf5oohgCBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Executar a Divis√£o do Dataset\n",
        "# Esta chamada CRIA a pasta de sa√≠da: /content/data/anime_dbz_split\n",
        "print(\"--- Passo 1: Executando a Divis√£o (SPLIT) dos dados ---\")\n",
        "split_train_val(\n",
        "    root_dir='/content/data/anime_dbz',  # Pasta de entrada (com Goku/ e Vegeta/)\n",
        "    train_ratio=0.8,\n",
        "    seed=42\n",
        ")\n",
        "print(\"Divis√£o conclu√≠da. Pasta /content/data/anime_dbz_split criada.\")\n",
        "\n",
        "\n",
        "# 2. Criar os DataLoaders a partir do diret√≥rio CORRETO (o que foi rec√©m-criado)\n",
        "print(\"\\n--- Passo 2: Criando DataLoaders a partir do diret√≥rio SPLIT ---\")\n",
        "if __name__ == '__main__':\n",
        "    TRAIN_LOADER, VAL_LOADER = create_dataloaders(\n",
        "        root_dir=\"/content/data/anime_dbz_split\", # Pasta que agora existe\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    if TRAIN_LOADER and VAL_LOADER:\n",
        "        # Teste de itera√ß√£o (s√≥ rodar√° se o tamanho do dataset for > 0)\n",
        "        print(\"\\nSucesso! Testando um batch de treino:\")\n",
        "        for images, labels in TRAIN_LOADER:\n",
        "            print(f\"Shape do batch de imagens (Batch Size, Channels, Height, Width): {images.shape}\")\n",
        "            print(f\"Labels do batch: {labels}\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ov_Msge3um",
        "outputId": "0cf37567-1ecb-4356-b96b-dbb714b08bac"
      },
      "id": "X6ov_Msge3um",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Passo 1: Executando a Divis√£o (SPLIT) dos dados ---\n",
            "Goku: 80 train, 20 val\n",
            "Vegeta: 80 train, 20 val\n",
            "Divis√£o conclu√≠da. Pasta /content/data/anime_dbz_split criada.\n",
            "\n",
            "--- Passo 2: Criando DataLoaders a partir do diret√≥rio SPLIT ---\n",
            "\n",
            "[DEBUG LOADER] Verificando diret√≥rios esperados:\n",
            "[DEBUG LOADER] Treino: /content/data/anime_dbz_split/train\n",
            "[DEBUG LOADER] Valida√ß√£o: /content/data/anime_dbz_split/val\n",
            "\n",
            "[DEBUG DATASET] Iniciando busca em: /content/data/anime_dbz_split/train\n",
            "[DEBUG DATASET] Classe 'Goku' adicionada com 80 imagens.\n",
            "[DEBUG DATASET] Classe 'Vegeta' adicionada com 80 imagens.\n",
            "\n",
            "[DEBUG DATASET] Iniciando busca em: /content/data/anime_dbz_split/val\n",
            "[DEBUG DATASET] Classe 'Goku' adicionada com 20 imagens.\n",
            "[DEBUG DATASET] Classe 'Vegeta' adicionada com 20 imagens.\n",
            "Datasets carregados: Treino (160 imagens), Valida√ß√£o (40 imagens)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/data/anime_dbz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2qG5Bjgd7Xc",
        "outputId": "291e6afe-669e-4d8e-f250-20d913fa53a5"
      },
      "id": "P2qG5Bjgd7Xc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Goku  Vegeta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ab6c9e",
      "metadata": {
        "id": "83ab6c9e"
      },
      "source": [
        "## Defini√ß√£o do Modelo\n",
        "\n",
        "Defina aqui o modelo que ser√° utilizado, sendo implementa√ß√£o pr√≥pria ou um modelo pr√©-treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7634074",
      "metadata": {
        "id": "f7634074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de693cfe-0900-4731-e979-e5671fe62668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 48.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo base ResNet18 carregado com pesos pr√©-treinados.\n",
            "Camada final (fc) modificada para 2 classes.\n",
            "\n",
            "Teste de output do modelo realizado com sucesso.\n",
            "Shape de sa√≠da (Batch Size, Classes): torch.Size([32, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def setup_model(num_classes=2, feature_extract=True):\n",
        "    \"\"\"\n",
        "    Define e inicializa o modelo ResNet18 pr√©-treinado.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): O n√∫mero de classes de sa√≠da (2 para Goku e Vegeta).\n",
        "        feature_extract (bool): Se True, congela os par√¢metros do corpo do modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Carregar o modelo ResNet18 pr√©-treinado no ImageNet\n",
        "    model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    print(\"Modelo base ResNet18 carregado com pesos pr√©-treinados.\")\n",
        "\n",
        "\n",
        "    if feature_extract:\n",
        "        for param in model_ft.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "    # Substituir a camada 'fc' por uma nova camada linear\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    print(f\"Camada final (fc) modificada para {num_classes} classes.\")\n",
        "\n",
        "    return model_ft\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    NUM_CLASSES = 2\n",
        "\n",
        "    # 1. Inicializar o Modelo\n",
        "    model = setup_model(num_classes=NUM_CLASSES, feature_extract=True)\n",
        "\n",
        "    # 2. Mover o modelo para a GPU, se dispon√≠vel\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # 3. Testar o Modelo (Passar um tensor de dados pelo modelo)\n",
        "    # Criamos um tensor simulando um batch de 32 imagens (cor: 3, tamanho: 224x224)\n",
        "    dummy_input = torch.randn(32, 3, 224, 224).to(device)\n",
        "\n",
        "    try:\n",
        "        output = model(dummy_input)\n",
        "        print(f\"\\nTeste de output do modelo realizado com sucesso.\")\n",
        "        print(f\"Shape de sa√≠da (Batch Size, Classes): {output.shape}\") # Deve ser [32, 2]\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao passar dados de teste pelo modelo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabbee06",
      "metadata": {
        "id": "dabbee06"
      },
      "source": [
        "## Treinamento\n",
        "\n",
        "Defina a fun√ß√£o de custo e o otimizador do modelo. Em seguida, implemente o c√≥digo de treinamento e treine-o. Ao final, exiba as curvas de treinamento e valida√ß√£o para a loss e a acur√°cia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d247d1dd",
      "metadata": {
        "id": "d247d1dd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class AnimeDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.class_to_idx = {'Goku': 0, 'Vegeta': 1}\n",
        "\n",
        "        for class_name, idx in self.class_to_idx.items():\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                for filename in os.listdir(class_path):\n",
        "                    fpath = os.path.join(class_path, filename)\n",
        "                    if os.path.isfile(fpath):\n",
        "                        self.image_paths.append(fpath)\n",
        "                        self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path = self.image_paths[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "\n",
        "        except Exception as e:\n",
        "            new_idx = random.randint(0, len(self) - 1)\n",
        "            return self.__getitem__(new_idx)\n",
        "\n",
        "def get_transforms(image_size=224):\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return train_transforms, val_transforms\n",
        "\n",
        "def create_dataloaders(root_dir, batch_size=32, image_size=224):\n",
        "    train_dir = os.path.join(root_dir, \"train\")\n",
        "    val_dir = os.path.join(root_dir, \"val\")\n",
        "    train_transforms, val_transforms = get_transforms(image_size)\n",
        "\n",
        "    try:\n",
        "        train_dataset = AnimeDataset(root_dir=train_dir, transform=train_transforms)\n",
        "        val_dataset = AnimeDataset(root_dir=val_dir, transform=val_transforms)\n",
        "\n",
        "        if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "             raise ValueError(\"Dataset vazio.\")\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        return train_dataloader, val_dataloader\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None\n",
        "\n",
        "def setup_model(num_classes=2, feature_extract=True):\n",
        "    model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    if feature_extract:\n",
        "        for param in model_ft.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model_ft\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=15):\n",
        "    since = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            history[f'{phase}_loss'].append(epoch_loss)\n",
        "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "def plot_curves(history):\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], 'bo-', label='Loss Treinamento')\n",
        "    plt.plot(epochs, history['val_loss'], 'ro-', label='Loss Valida√ß√£o')\n",
        "    plt.title('Curvas de Loss')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['train_acc'], 'bo-', label='Acur√°cia Treinamento')\n",
        "    plt.plot(epochs, history['val_acc'], 'ro-', label='Acur√°cia Valida√ß√£o')\n",
        "    plt.title('Curvas de Acur√°cia')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('Acur√°cia')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    DATA_DIR = \"/content/data/anime_dbz_split\"\n",
        "    NUM_CLASSES = 2\n",
        "    NUM_EPOCHS = 15\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    train_loader, val_loader = create_dataloaders(DATA_DIR, batch_size=32)\n",
        "\n",
        "    if train_loader is not None and val_loader is not None:\n",
        "        dataloaders_dict = {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "        model_ft = setup_model(NUM_CLASSES, feature_extract=True)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        params_to_update = [p for p in model_ft.parameters() if p.requires_grad]\n",
        "        optimizer_ft = optim.Adam(params_to_update, lr=LEARNING_RATE)\n",
        "\n",
        "        _, history = train_model(\n",
        "            model_ft,\n",
        "            dataloaders_dict,\n",
        "            criterion,\n",
        "            optimizer_ft,\n",
        "            num_epochs=NUM_EPOCHS\n",
        "        )\n",
        "\n",
        "        plot_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85323b96",
      "metadata": {
        "id": "85323b96"
      },
      "source": [
        "## Infer√™ncia\n",
        "\n",
        "Calcule algumas m√©tricas como acur√°cia, matriz de confus√£o, etc. Em seguida, teste o modelo em novas imagens das classes correspondentes mas de outras fontes (outro buscador, fotos pr√≥prias, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c63e2a",
      "metadata": {
        "id": "21c63e2a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# --- FUN√á√ïES ESSENCIAIS DE ETAPAS ANTERIORES ---\n",
        "\n",
        "class AnimeDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.class_to_idx = {'Goku': 0, 'Vegeta': 1}\n",
        "\n",
        "        for class_name, idx in self.class_to_idx.items():\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                for filename in os.listdir(class_path):\n",
        "                    fpath = os.path.join(class_path, filename)\n",
        "                    if os.path.isfile(fpath):\n",
        "                        self.image_paths.append(fpath)\n",
        "                        self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path = self.image_paths[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "\n",
        "        except Exception as e:\n",
        "            new_idx = random.randint(0, len(self) - 1)\n",
        "            return self.__getitem__(new_idx)\n",
        "\n",
        "def get_transforms(image_size=224):\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return train_transforms, val_transforms\n",
        "\n",
        "def create_dataloaders(root_dir, batch_size=32, image_size=224):\n",
        "    train_dir = os.path.join(root_dir, \"train\")\n",
        "    val_dir = os.path.join(root_dir, \"val\")\n",
        "    train_transforms, val_transforms = get_transforms(image_size)\n",
        "\n",
        "    try:\n",
        "        train_dataset = AnimeDataset(root_dir=train_dir, transform=train_transforms)\n",
        "        val_dataset = AnimeDataset(root_dir=val_dir, transform=val_transforms)\n",
        "\n",
        "        if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "             raise ValueError(\"Dataset vazio.\")\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        return train_dataloader, val_dataloader\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None\n",
        "\n",
        "def setup_model(num_classes=2, feature_extract=True):\n",
        "    model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    if feature_extract:\n",
        "        for param in model_ft.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model_ft\n",
        "\n",
        "# --- FUN√á√ïES DE INFER√äNCIA E AVALIA√á√ÉO ---\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    total_loss = running_loss / len(dataloader.dataset)\n",
        "    total_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return total_acc.item(), total_loss, cm\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names=['Goku', 'Vegeta']):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Matriz de Confus√£o')\n",
        "    plt.xlabel('Predito')\n",
        "    plt.ylabel('Real')\n",
        "    plt.show()\n",
        "\n",
        "def test_new_image(model, image_path, class_names=['Goku', 'Vegeta']):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    _, val_transforms = get_transforms(image_size=224)\n",
        "\n",
        "    try:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "    except:\n",
        "        return\n",
        "\n",
        "    input_tensor = val_transforms(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)[0]\n",
        "        _, predicted_class_idx = torch.max(output, 1)\n",
        "\n",
        "    predicted_label = class_names[predicted_class_idx.item()]\n",
        "    confidence = probabilities[predicted_class_idx.item()].item() * 100\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"PREDI√á√ÉO: {predicted_label} ({confidence:.2f}%)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --- BLOCO PRINCIPAL DE EXECU√á√ÉO (INFER√äNCIA) ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    DATA_DIR = \"/content/data/anime_dbz_split\"\n",
        "    NUM_CLASSES = 2\n",
        "\n",
        "    # 1. Carregar DataLoaders\n",
        "    _, val_loader = create_dataloaders(DATA_DIR, batch_size=32)\n",
        "\n",
        "    # 2. Configurar Modelo\n",
        "    modelo_final = setup_model(NUM_CLASSES, feature_extract=True)\n",
        "\n",
        "    # 3. Simular Carga de Pesos Treinados (SUBSTITUA PELA CARGA REAL DOS SEUS PESOS TREINADOS)\n",
        "    # Exemplo: modelo_final.load_state_dict(torch.load('melhores_pesos.pt'))\n",
        "    # Para fins de demonstra√ß√£o, o modelo inicializado ser√° usado.\n",
        "\n",
        "    print(\"--- INFER√äNCIA NO CONJUNTO DE VALIDA√á√ÉO ---\")\n",
        "\n",
        "    if val_loader:\n",
        "        acc, loss, cm = evaluate_model(modelo_final, val_loader)\n",
        "\n",
        "        print(f\"Loss na Valida√ß√£o: {loss:.4f}\")\n",
        "        print(f\"Acur√°cia na Valida√ß√£o: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "        plot_confusion_matrix(cm)\n",
        "\n",
        "    print(\"\\n--- TESTE EM NOVAS IMAGENS (SIMULA√á√ÉO) ---\")\n",
        "\n",
        "    # 4. Configura√ß√£o de Novas Imagens de Teste\n",
        "    # SUBSTITUA ESTA LISTA COM OS CAMINHOS REAIS DE NOVAS IMAGENS BAIXADAS EXTERNAMENTE!\n",
        "    imagens_teste_simuladas = [\n",
        "        '/content/goku_ssj3_new.jpg',\n",
        "        '/content/vegeta_blue_new.jpg',\n",
        "    ]\n",
        "\n",
        "    if not any(os.path.exists(p) for p in imagens_teste_simuladas):\n",
        "         print(\"Nenhum caminho de imagem de teste externo v√°lido fornecido. Teste ignorado.\")\n",
        "    else:\n",
        "        for i, img_path in enumerate(imagens_teste_simuladas):\n",
        "            if os.path.exists(img_path):\n",
        "                test_new_image(modelo_final, img_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}